{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "enc_dec_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "source": [
        "## NMT with attention (jointly learning to align & translate)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j6GUT86ilLP",
        "outputId": "db8cebb1-a60a-4071-9e3f-b92ff92be657"
      },
      "source": [
        "# bleu score needs\r\n",
        "!pip install torchtext==0.6.0\r\n",
        "\r\n",
        "# spacy language model loads\r\n",
        "!python -m spacy download en\r\n",
        "!python -m spacy download de"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (0.1.94)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.19.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dagFjllKip2f"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "import torchtext\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import spacy\r\n",
        "import random\r\n",
        "import math\r\n",
        "import time"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMP7_YS8ip4f"
      },
      "source": [
        "# For deterministic results set seed\r\n",
        "\r\n",
        "SEED = 555\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE-ZNS72ip6p"
      },
      "source": [
        "# Load Spacy language models for tokenizing\r\n",
        "\r\n",
        "spacy_de = spacy.load('de')\r\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhbcf6w6ip8v"
      },
      "source": [
        "def tokenize_de(text):\r\n",
        "    # Tokenizes German text from a string into a list of strings (tokens) and reverses it\r\n",
        "    # As source seq is fed in reverse order in basic enc_dec\r\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\r\n",
        "\r\n",
        "def tokenize_en(text):\r\n",
        "    # Tokenizes English text from a string into a list of strings (tokens)\r\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUBwSW9lip_C"
      },
      "source": [
        "# Field() of TorchText: Does tokenization according to fx, appends start and end tokens and lowers() case.\r\n",
        "# include length will give a tuple for batch.src: (batch of numericalized source sentence as a tensor, non-padded lengths of each source sentence within the batch)\r\n",
        "\r\n",
        "SRC = Field(tokenize = tokenize_de, init_token = '<sos>', eos_token = '<eos>', lower = True, include_lengths = True)\r\n",
        "TRG = Field(tokenize = tokenize_en, init_token = '<sos>', eos_token = '<eos>', lower = True)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIFhLSQWiqBW"
      },
      "source": [
        "# Split data. Assigns source as German, target as English\r\n",
        "\r\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SRC, TRG))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsRR-0pciqDj",
        "outputId": "80197e96-f4fc-4c38-8e78-cdef85707210"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\r\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\r\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6wJvndHiqFq"
      },
      "source": [
        "# Build lang vocabulary. Discard words which occur less than x(min_freq) times\r\n",
        "\r\n",
        "SRC.build_vocab(train_data, min_freq = 2)\r\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ry7ALMiqHu",
        "outputId": "ad4ee8a7-8d0d-4178-9e71-54c93db34cdd"
      },
      "source": [
        "# Use Cuda if available\r\n",
        "\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "print(device)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cudI1yhtiqJ_"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "# Create iterators to get a batch of seq ip/op. Iterator automatically handles padding sequences to same length\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), batch_size = BATCH_SIZE, sort_within_batch = True, sort_key = lambda x : len(x.src), device = device)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FenXXVYiqMC"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "  def __init__(self, input_dim, embed_dim, enc_hid_dim, dec_hid_dim, dropout):\r\n",
        "    super().__init__()\r\n",
        "    self.embed = nn.Embedding(input_dim, embed_dim)\r\n",
        "    self.rnn = nn.GRU(embed_dim, enc_hid_dim, bidirectional = True, dropout = dropout)\r\n",
        "    self.fc = nn.Linear(2*enc_hid_dim, dec_hid_dim)\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "    self.verbose = True\r\n",
        "  \r\n",
        "  def forward(self, src, src_len):\r\n",
        "    if self.verbose:\r\n",
        "      print(f'Src shape: {src.shape}\\n')\r\n",
        "    # src: [src_len, bs]\r\n",
        "    # src_len: [bs]\r\n",
        "    embedded = self.dropout(self.embed(src))\r\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.cpu())\r\n",
        "\r\n",
        "    # hs is from the final non-padded element in the sequence not packed. op is packed.\r\n",
        "    packed_output, hs = self.rnn(packed_embedded)\r\n",
        "    if self.verbose:\r\n",
        "      print(f'Enc hs shape: {hs.shape}\\n')\r\n",
        "    # op: [seq_len, bs, n_dir*enc_hid_dim]\r\n",
        "    # hs: [n_lay*n_dir, bs, enc_hid_dim]\r\n",
        "\r\n",
        "    outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output)\r\n",
        "    # all hidden states obtained when the input is a pad token are all zeros\r\n",
        "\r\n",
        "    if self.verbose:\r\n",
        "      print(f'Unpacked Enc Op shape: {outputs.shape}\\n')\r\n",
        "\r\n",
        "    hidden = torch.tanh(self.fc(torch.cat((hs[-2,:,:], hs[-1,:,:]), dim = 1)))\r\n",
        "    self.verbose = False\r\n",
        "    return outputs, hidden"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3JiMuVmjKVo"
      },
      "source": [
        "# mask to not pay attention to hs formed when ip is pad token\r\n",
        "\r\n",
        "class Attention(nn.Module):\r\n",
        "  def __init__(self, enc_hid_dim, dec_hid_dim):\r\n",
        "    super().__init__()\r\n",
        "    self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\r\n",
        "    self.v = nn.Linear(dec_hid_dim, 1, bias = False)\r\n",
        "\r\n",
        "  def forward(self, hidden, encoder_outputs, mask):\r\n",
        "    batch_size = encoder_outputs.shape[1]\r\n",
        "    src_len = encoder_outputs.shape[0]\r\n",
        "    \r\n",
        "    #repeat decoder hidden state src_len times\r\n",
        "    hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\r\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
        "    \r\n",
        "    #hidden = [batch size, src len, dec hid dim]\r\n",
        "    #encoder_outputs = [batch size, src len, enc hid dim * 2]\r\n",
        "    \r\n",
        "    energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \r\n",
        "    #energy = [batch size, src len, dec hid dim]\r\n",
        "\r\n",
        "    attention = self.v(energy).squeeze(2)\r\n",
        "    #attention = [batch size, src len]\r\n",
        "    \r\n",
        "    attention = attention.masked_fill(mask == 0, -1e10)\r\n",
        "    return F.softmax(attention, dim = 1)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oCKz_bqjKX8"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "  def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\r\n",
        "    super().__init__()\r\n",
        "    self.output_dim = output_dim\r\n",
        "    self.attention = attention\r\n",
        "    self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "    self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\r\n",
        "    self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "    \r\n",
        "  def forward(self, input, hidden, encoder_outputs, mask):  \r\n",
        "      input = input.unsqueeze(0)\r\n",
        "      #input = [1, batch size]\r\n",
        "      \r\n",
        "      embedded = self.dropout(self.embedding(input))\r\n",
        "      #embedded = [1, batch size, emb dim]\r\n",
        "      \r\n",
        "      a = self.attention(hidden, encoder_outputs, mask)\r\n",
        "      #a = [batch size, src len]\r\n",
        "      \r\n",
        "      a = a.unsqueeze(1)\r\n",
        "      #a = [batch size, 1, src len]\r\n",
        "      \r\n",
        "      encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
        "      #encoder_outputs = [batch size, src len, enc hid dim * 2]\r\n",
        "      \r\n",
        "      weighted = torch.bmm(a, encoder_outputs)\r\n",
        "      #weighted = [batch size, 1, enc hid dim * 2]\r\n",
        "      \r\n",
        "      weighted = weighted.permute(1, 0, 2)\r\n",
        "      #weighted = [1, batch size, enc hid dim * 2]\r\n",
        "      \r\n",
        "      rnn_input = torch.cat((embedded, weighted), dim = 2)\r\n",
        "      #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\r\n",
        "          \r\n",
        "      output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\r\n",
        "      \r\n",
        "      embedded = embedded.squeeze(0)\r\n",
        "      output = output.squeeze(0)\r\n",
        "      weighted = weighted.squeeze(0)\r\n",
        "      \r\n",
        "      prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\r\n",
        "      \r\n",
        "      #prediction = [batch size, output dim]\r\n",
        "      return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1p4RF0ZH9oj"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "  def __init__(self, encoder, decoder, src_pad_idx, device):\r\n",
        "    super().__init__()\r\n",
        "    self.encoder = encoder\r\n",
        "    self.decoder = decoder\r\n",
        "    self.src_pad_idx = src_pad_idx\r\n",
        "    self.device = device\r\n",
        "      \r\n",
        "  def create_mask(self, src):\r\n",
        "    mask = (src != self.src_pad_idx).permute(1, 0)\r\n",
        "    return mask\r\n",
        "      \r\n",
        "  def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):                \r\n",
        "    batch_size = src.shape[1]\r\n",
        "    trg_len = trg.shape[0]\r\n",
        "    trg_vocab_size = self.decoder.output_dim\r\n",
        "    \r\n",
        "    # tensor to store decoder outputs\r\n",
        "    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "\r\n",
        "    encoder_outputs, hidden = self.encoder(src, src_len)\r\n",
        "            \r\n",
        "    #first input to the decoder is the <sos> tokens\r\n",
        "    input = trg[0,:]\r\n",
        "    \r\n",
        "    mask = self.create_mask(src)\r\n",
        "    for t in range(1, trg_len):\r\n",
        "      output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\r\n",
        "      outputs[t] = output\r\n",
        "      \r\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "      top1 = output.argmax(1) \r\n",
        "      input = trg[t] if teacher_force else top1\r\n",
        "        \r\n",
        "    return outputs"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMCipxd9H9mQ",
        "outputId": "8ee01265-265a-419f-e3ff-a0ea7a4d3efc"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "ENC_EMB_DIM = 256\r\n",
        "DEC_EMB_DIM = 256\r\n",
        "ENC_HID_DIM = 512\r\n",
        "DEC_HID_DIM = 512\r\n",
        "ENC_DROPOUT = 0.5\r\n",
        "DEC_DROPOUT = 0.5\r\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\r\n",
        "\r\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\r\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\r\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoidjKc6H9kI",
        "outputId": "08f7fa0a-56b7-4dff-be43-98995c4e7b39"
      },
      "source": [
        "def init_weights(m):\r\n",
        "  for name, param in m.named_parameters():\r\n",
        "    if 'weight' in name:\r\n",
        "      nn.init.normal_(param.data, mean=0, std=0.01)\r\n",
        "    else:\r\n",
        "      nn.init.constant_(param.data, 0)\r\n",
        "            \r\n",
        "model.apply(init_weights)\r\n",
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 20,518,917 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWSrlvd7H9hp"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\r\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S54cKxTcJVJO"
      },
      "source": [
        "# Begin train\r\n",
        "\r\n",
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "  # sets mode to train\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  epoch_loss = 0\r\n",
        "\r\n",
        "  for i, batch in enumerate(iterator):\r\n",
        "    # pull the src, tgt\r\n",
        "    src, src_len = batch.src\r\n",
        "    tgt = batch.trg\r\n",
        "\r\n",
        "    # zero the grad calculated from last batch\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    # send to model\r\n",
        "    op = model(src, src_len, tgt)\r\n",
        "\r\n",
        "    output_dim = op.shape[-1]\r\n",
        "    op = op[1:].view(-1, output_dim)\r\n",
        "    tgt = tgt[1:].view(-1)\r\n",
        "\r\n",
        "    loss = criterion(op, tgt)\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "    epoch_loss += loss.item()\r\n",
        "\r\n",
        "  return epoch_loss / len(iterator)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jkh3bl2VWp9"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "  model.eval()\r\n",
        "  epoch_loss = 0\r\n",
        "  \r\n",
        "  with torch.no_grad():\r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "      src, src_len = batch.src\r\n",
        "      trg = batch.trg\r\n",
        "\r\n",
        "      output = model(src, src_len, trg, 0) \r\n",
        "      output_dim = output.shape[-1]\r\n",
        "      \r\n",
        "      output = output[1:].view(-1, output_dim)\r\n",
        "      trg = trg[1:].view(-1)\r\n",
        "\r\n",
        "      loss = criterion(output, trg)\r\n",
        "      epoch_loss += loss.item()\r\n",
        "      \r\n",
        "  return epoch_loss / len(iterator)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jetUjcUH9fV"
      },
      "source": [
        "# record times\r\n",
        "\r\n",
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffEuXTmmH9dH",
        "outputId": "9b51b76f-3684-481e-d99b-8a2ec7a1654e"
      },
      "source": [
        "# Begin training actually\r\n",
        "\r\n",
        "N_EPOCHS = 10\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "  start_time = time.time()\r\n",
        "\r\n",
        "  train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "  valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "\r\n",
        "  end_time = time.time()\r\n",
        "\r\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "\r\n",
        "  if valid_loss < best_valid_loss:\r\n",
        "    best_valid_loss = valid_loss\r\n",
        "    torch.save(model.state_dict(), 'enc_dec-model.pt')\r\n",
        "\r\n",
        "  print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "  print(f'\\tValid Loss: {valid_loss:.3f} | Valid PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Src shape: torch.Size([21, 128])\n",
            "\n",
            "Enc hs shape: torch.Size([2, 128, 512])\n",
            "\n",
            "Unpacked Enc Op shape: torch.Size([21, 128, 1024])\n",
            "\n",
            "Epoch: 01 | Time: 0m 44s\n",
            "\tTrain Loss: 5.068 | Train PPL: 158.886\n",
            "\tValid Loss: 4.706 | Valid PPL: 110.658\n",
            "Epoch: 02 | Time: 0m 46s\n",
            "\tTrain Loss: 3.983 | Train PPL:  53.653\n",
            "\tValid Loss: 4.081 | Valid PPL:  59.191\n",
            "Epoch: 03 | Time: 0m 47s\n",
            "\tTrain Loss: 3.237 | Train PPL:  25.451\n",
            "\tValid Loss: 3.588 | Valid PPL:  36.152\n",
            "Epoch: 04 | Time: 0m 47s\n",
            "\tTrain Loss: 2.752 | Train PPL:  15.675\n",
            "\tValid Loss: 3.405 | Valid PPL:  30.117\n",
            "Epoch: 05 | Time: 0m 47s\n",
            "\tTrain Loss: 2.420 | Train PPL:  11.248\n",
            "\tValid Loss: 3.269 | Valid PPL:  26.274\n",
            "Epoch: 06 | Time: 0m 46s\n",
            "\tTrain Loss: 2.135 | Train PPL:   8.460\n",
            "\tValid Loss: 3.184 | Valid PPL:  24.141\n",
            "Epoch: 07 | Time: 0m 46s\n",
            "\tTrain Loss: 1.932 | Train PPL:   6.903\n",
            "\tValid Loss: 3.206 | Valid PPL:  24.671\n",
            "Epoch: 08 | Time: 0m 46s\n",
            "\tTrain Loss: 1.733 | Train PPL:   5.659\n",
            "\tValid Loss: 3.313 | Valid PPL:  27.471\n",
            "Epoch: 09 | Time: 0m 46s\n",
            "\tTrain Loss: 1.579 | Train PPL:   4.852\n",
            "\tValid Loss: 3.262 | Valid PPL:  26.092\n",
            "Epoch: 10 | Time: 0m 46s\n",
            "\tTrain Loss: 1.462 | Train PPL:   4.316\n",
            "\tValid Loss: 3.286 | Valid PPL:  26.744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b5zFNpzHvQb",
        "outputId": "c3be291d-5534-403a-95f8-11cf7f5586df"
      },
      "source": [
        "# When testing, directly load trained model and run\r\n",
        "# Load trained model, test set\r\n",
        "\r\n",
        "trained_model = 'enc_dec-model.pt'\r\n",
        "\r\n",
        "model.load_state_dict(torch.load(trained_model))\r\n",
        "test_loss = evaluate(model, test_iterator, criterion)\r\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.206 | Test PPL:  24.684 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqQXVgfQHvOG"
      },
      "source": [
        "def translate(sentence, src_field, tgt_field, model, device, max_len = 50):\r\n",
        "  # eval mode\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  # tokenize src if it's a string\r\n",
        "  if isinstance(sentence, str):\r\n",
        "    nlp = spacy.load('de')\r\n",
        "    tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "  else:\r\n",
        "    tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "  # Add <sos>, <eos>\r\n",
        "  tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "  # Numericalize seq\r\n",
        "  src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "  # make tensor of src seq\r\n",
        "  src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\r\n",
        "  src_len = torch.LongTensor([len(src_indexes)]).to(device)\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    op, hs = model.encoder(src_tensor, src_len)\r\n",
        "  \r\n",
        "  mask = model.create_mask(src_tensor)\r\n",
        "  tgt_indexes = [tgt_field.vocab.stoi[tgt_field.init_token]]\r\n",
        "  attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\r\n",
        "\r\n",
        "  for i in range(max_len):\r\n",
        "    # each time set the last token of tgt_tensor as input to decoder. Here no teacher_force\r\n",
        "    # 1st time its <sos>, then prev predicted tok by decoder\r\n",
        "    tgt_tensor = torch.LongTensor([tgt_indexes[-1]]).to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      output, hs, attention = model.decoder(tgt_tensor, hs, op, mask)\r\n",
        "\r\n",
        "    attentions[i] = attention\r\n",
        "    pred_token = output.argmax(1).item()\r\n",
        "    tgt_indexes.append(pred_token)\r\n",
        "\r\n",
        "    if pred_token == tgt_field.vocab.stoi[tgt_field.eos_token]:\r\n",
        "      break\r\n",
        "    \r\n",
        "  # Get back the predicted tgt tokens\r\n",
        "  tgt_tokens = [tgt_field.vocab.itos[i] for i in tgt_indexes]\r\n",
        "  # cut off <sos>\r\n",
        "  return tgt_tokens[1:], attentions[:len(tgt_tokens)-1]"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46jeZdKAHvMD",
        "outputId": "1a6a1986-7994-4a62-d64d-8b43b2889388"
      },
      "source": [
        "example_idx = 25\r\n",
        "\r\n",
        "src = vars(train_data.examples[example_idx])['src']\r\n",
        "tgt = vars(train_data.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'actual translation = {tgt}')\r\n",
        "translation, _ = translate(src, SRC, TRG, model, device)\r\n",
        "print(f'predicted translation = {translation}')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['.', 'straßenszene', 'einer', 'gemälde', 'ein', 'betrachtet', 'und', 'gehweg', 'belebten', 'einem', 'auf', 'steht', 'mantel', 'blauen', 'einem', 'in', 'person', 'eine']\n",
            "actual translation = ['a', 'person', 'dressed', 'in', 'a', 'blue', 'coat', 'is', 'standing', 'in', 'on', 'a', 'busy', 'sidewalk', ',', 'studying', 'painting', 'of', 'a', 'street', 'scene', '.']\n",
            "predicted translation = ['a', 'person', 'in', 'a', 'blue', 'coat', 'is', 'standing', 'on', 'a', 'sidewalk', 'sidewalk', 'looking', 'at', 'a', 'painting', 'a', 'a', 'street', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58rhJci9jKcC",
        "outputId": "33a22ccc-9908-4ca9-c5e1-49064a0077d0"
      },
      "source": [
        "example_idx = 10\r\n",
        "\r\n",
        "src = vars(train_data.examples[example_idx])['src']\r\n",
        "tgt = vars(train_data.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'actual translation = {tgt}')\r\n",
        "translation, _ = translate(src, SRC, TRG, model, device)\r\n",
        "print(f'predicted translation = {translation}')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['.', 'springen', 'nacheinander', 'die', ',', 'mädchen', 'fünf', 'mit', 'ballettklasse', 'eine']\n",
            "actual translation = ['a', 'ballet', 'class', 'of', 'five', 'girls', 'jumping', 'in', 'sequence', '.']\n",
            "predicted translation = ['a', 'class', 'of', 'five', 'five', 'girls', 'jump', 'in', 'sequence', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMrq-bb2jKec",
        "outputId": "396fe2cb-1196-44f6-e41e-0188d24152a4"
      },
      "source": [
        "example_idx = 29\r\n",
        "\r\n",
        "src = vars(train_data.examples[example_idx])['src']\r\n",
        "tgt = vars(train_data.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'actual translation = {tgt}')\r\n",
        "translation, _ = translate(src, SRC, TRG, model, device)\r\n",
        "print(f'predicted translation = {translation}')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['.', 'lächelt', 'und', 'an', 'etwas', 'blickt', 'jacke', 'schwarz-gelben', 'einer', 'in', 'mann', 'junger', 'ein']\n",
            "actual translation = ['a', 'young', 'man', 'in', 'a', 'black', 'and', 'yellow', 'jacket', 'is', 'gazing', 'at', 'something', 'and', 'smiling', '.']\n",
            "predicted translation = ['a', 'young', 'man', 'in', 'a', 'black', 'and', 'white', 'jacket', 'looks', 'looking', 'at', 'something', 'and', 'smiles', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5fFcEw6jKgr"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\r\n",
        "\r\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\r\n",
        "  trgs = []\r\n",
        "  pred_trgs = []\r\n",
        "\r\n",
        "  for datum in data:\r\n",
        "    src = vars(datum)['src']\r\n",
        "    trg = vars(datum)['trg']\r\n",
        "    pred_trg, _ = translate(src, src_field, trg_field, model, device, max_len)\r\n",
        "    \r\n",
        "    # cut off <eos>\r\n",
        "    pred_trg = pred_trg[:-1]\r\n",
        "    \r\n",
        "    pred_trgs.append(pred_trg)\r\n",
        "    trgs.append([trg])\r\n",
        "      \r\n",
        "  return bleu_score(pred_trgs, trgs)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XGeAli1jKjM",
        "outputId": "ae2910f6-ccc6-4f7a-8ddb-f3348bde93b5"
      },
      "source": [
        "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'BLEU score w attention enc_dec = {bleu_score*100:.2f}')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score w attention enc_dec = 29.03\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}